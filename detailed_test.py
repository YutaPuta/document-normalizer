#!/usr/bin/env python3
"""
è©³ç´°ãªå‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ
å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®æ©Ÿèƒ½ã‚’å€‹åˆ¥ã«æ¤œè¨¼
"""

import sys
import json
import yaml
from pathlib import Path

def test_yaml_config_loading():
    """YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°ç¢ºèª"""
    print("=== YAMLè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°ãƒ†ã‚¹ãƒˆ ===\n")
    
    config_dir = Path("config")
    
    # 1. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ã®è©³ç´°
    global_yaml = config_dir / "mapping" / "global.yaml"
    with open(global_yaml, 'r', encoding='utf-8') as f:
        global_config = yaml.safe_load(f)
    
    print("1. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°è©³ç´°:")
    mappings = global_config.get('mappings', {})
    for field_name, config in mappings.items():
        sources = config.get('from', [])
        transforms = config.get('transform', [])
        default = config.get('default', None)
        print(f"   ğŸ“„ {field_name}:")
        print(f"      ã‚½ãƒ¼ã‚¹: {sources[:3]}{'...' if len(sources) > 3 else ''}")
        print(f"      å¤‰æ›: {transforms}")
        if default:
            print(f"      ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {default}")
    
    # 2. è«‹æ±‚æ›¸å›ºæœ‰ãƒãƒƒãƒ”ãƒ³ã‚°
    invoice_yaml = config_dir / "mapping" / "doc_type" / "INVOICE.yaml"
    with open(invoice_yaml, 'r', encoding='utf-8') as f:
        invoice_config = yaml.safe_load(f)
    
    print(f"\n2. è«‹æ±‚æ›¸å›ºæœ‰ãƒãƒƒãƒ”ãƒ³ã‚°:")
    invoice_mappings = invoice_config.get('mappings', {})
    for field_name, config in invoice_mappings.items():
        sources = config.get('from', [])
        print(f"   ğŸ“„ {field_name}: {sources}")
    
    # æ˜ç´°è¡Œãƒ†ãƒ¼ãƒ–ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
    lines_config = invoice_config.get('lines', {})
    if 'table' in lines_config:
        table_config = lines_config['table']
        headers = table_config.get('headers', {})
        defaults = table_config.get('defaults', {})
        print(f"   ğŸ“Š ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼:")
        for field, patterns in headers.items():
            print(f"      {field}: {patterns}")
        print(f"   ğŸ“Š ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤: {defaults}")
    
    # å¾Œå‡¦ç†è¨ˆç®—
    post_compute = invoice_config.get('post_compute', [])
    if post_compute:
        print(f"   ğŸ§® å¾Œå‡¦ç†è¨ˆç®—: {len(post_compute)} ãƒ«ãƒ¼ãƒ«")
        for i, rule in enumerate(post_compute, 1):
            preview = rule.replace('\n', ' ')[:60]
            print(f"      ãƒ«ãƒ¼ãƒ«{i}: {preview}...")

def test_vendor_classification():
    """ãƒ™ãƒ³ãƒ€ãƒ¼åˆ†é¡ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ™ãƒ³ãƒ€ãƒ¼åˆ†é¡è©³ç´°ãƒ†ã‚¹ãƒˆ ===\n")
    
    config_dir = Path("config")
    vendor_yaml = config_dir / "classifier" / "vendors.yaml"
    
    with open(vendor_yaml, 'r', encoding='utf-8') as f:
        vendor_config = yaml.safe_load(f)
    
    # å„ãƒ™ãƒ³ãƒ€ãƒ¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ç¢ºèª
    for vendor_name, patterns in vendor_config.items():
        if vendor_name in ['default_patterns', 'description']:
            continue
        
        # patterns ãŒè¾æ›¸ã‹ãƒã‚§ãƒƒã‚¯    
        if not isinstance(patterns, dict):
            print(f"ğŸ¢ {vendor_name}: è¨­å®šå½¢å¼ã‚¨ãƒ©ãƒ¼ (å€¤: {patterns})")
            continue
            
        print(f"ğŸ¢ {vendor_name}:")
        
        for pattern_type, values in patterns.items():
            if pattern_type == 'company_names':
                print(f"   ä¼šç¤¾å: {values}")
            elif pattern_type == 'phone_patterns':
                print(f"   é›»è©±ç•ªå·: {values}")
            elif pattern_type == 'domains':
                print(f"   ãƒ‰ãƒ¡ã‚¤ãƒ³: {values}")
            elif pattern_type == 'addresses':
                print(f"   ä½æ‰€: {values}")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª
    default_patterns = vendor_config.get('default_patterns', {})
    if default_patterns:
        print(f"\nğŸ”§ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³:")
        for pattern_type, values in default_patterns.items():
            print(f"   {pattern_type}: {values[:2]}...")

def test_validation_rules():
    """æ¤œè¨¼ãƒ«ãƒ¼ãƒ«ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    print("\n=== æ¤œè¨¼ãƒ«ãƒ¼ãƒ«è©³ç´°ãƒ†ã‚¹ãƒˆ ===\n")
    
    config_dir = Path("config")
    rules_yaml = config_dir / "validation" / "rules.yaml"
    
    with open(rules_yaml, 'r', encoding='utf-8') as f:
        rules_config = yaml.safe_load(f)
    
    # é‡‘é¡ãƒã‚§ãƒƒã‚¯
    amount_checks = rules_config.get('amount_checks', {})
    print("ğŸ’° é‡‘é¡ãƒã‚§ãƒƒã‚¯:")
    for check_name, value in amount_checks.items():
        print(f"   {check_name}: {value}")
    
    # æ—¥ä»˜ãƒã‚§ãƒƒã‚¯
    date_checks = rules_config.get('date_checks', {})
    print(f"\nğŸ“… æ—¥ä»˜ãƒã‚§ãƒƒã‚¯:")
    for check_name, value in date_checks.items():
        print(f"   {check_name}: {value}")
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    required_fields = rules_config.get('required_fields', {})
    print(f"\nğŸ“‹ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:")
    for doc_type, fields in required_fields.items():
        print(f"   {doc_type}: {fields}")
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ¶ç´„
    field_constraints = rules_config.get('field_constraints', {})
    print(f"\nğŸ” ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åˆ¶ç´„:")
    for field_path, constraints in field_constraints.items():
        print(f"   {field_path}: {constraints}")

def test_transform_functions_detailed():
    """å¤‰æ›é–¢æ•°ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    print("\n=== å¤‰æ›é–¢æ•°è©³ç´°ãƒ†ã‚¹ãƒˆ ===\n")
    
    test_cases = [
        # æ—¥æœ¬èªé–¢é€£
        ("ä»¤å’Œ6å¹´1æœˆ15æ—¥", "å’Œæš¦â†’è¥¿æš¦å¤‰æ›"),
        ("å¹³æˆ31å¹´4æœˆ30æ—¥", "å’Œæš¦â†’è¥¿æš¦å¤‰æ›ï¼ˆå¹³æˆæœ€å¾Œï¼‰"),
        ("ï¼’ï¼ï¼’ï¼”å¹´ï¼‘ï¼’æœˆï¼“ï¼‘æ—¥", "å…¨è§’æ•°å­—â†’åŠè§’å¤‰æ›"),
        
        # é€šè²¨é–¢é€£
        ("ï¿¥1,234,567", "é€šè²¨è¨˜å·é™¤å»"),
        ("1,234,567å††", "å††ãƒãƒ¼ã‚¯é™¤å»"),
        ("$1,234.56", "ãƒ‰ãƒ«è¨˜å·é™¤å»"),
        
        # é›»è©±ç•ªå·é–¢é€£
        ("ï¼ï¼“ï¼ï¼‘ï¼’ï¼“ï¼”ï¼ï¼•ï¼–ï¼—ï¼˜", "å…¨è§’é›»è©±ç•ªå·â†’åŠè§’"),
        ("03(1234)5678", "é›»è©±ç•ªå·æ­£è¦åŒ–"),
        ("090-1234-5678", "æºå¸¯é›»è©±ç•ªå·"),
        
        # éƒµä¾¿ç•ªå·é–¢é€£
        ("ã€’ï¼‘ï¼ï¼ï¼ï¼ï¼ï¼ï¼‘", "å…¨è§’éƒµä¾¿ç•ªå·â†’åŠè§’"),
        ("1000001", "éƒµä¾¿ç•ªå·ãƒã‚¤ãƒ•ãƒ³æŒ¿å…¥"),
        
        # æ–‡å­—åˆ—å‡¦ç†
        ("  ã€€æ ªå¼ä¼šç¤¾ã‚¨ã‚°ã‚¶ãƒ³ãƒ—ãƒ«ã€€  ", "å‰å¾Œç©ºç™½é™¤å»"),
        ("ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§", "å…¨è§’è‹±å­—â†’åŠè§’"),
        ("ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼", "å…¨è§’æ•°å­—â†’åŠè§’"),
    ]
    
    for input_val, description in test_cases:
        # æ‰‹å‹•ã§å¤‰æ›ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆå®Ÿéš›ã®å¤‰æ›é–¢æ•°ã‚’å‘¼ã³å‡ºã™ä»£ã‚ã‚Šï¼‰
        result = simulate_transform(input_val)
        print(f"ğŸ”„ {description}")
        print(f"   å…¥åŠ›: '{input_val}'")
        print(f"   å‡ºåŠ›: '{result}'\n")

def simulate_transform(input_val):
    """å¤‰æ›å‡¦ç†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
    result = input_val
    
    # å’Œæš¦å¤‰æ›
    if "ä»¤å’Œ6å¹´" in result:
        result = "2024-01-15"
    elif "å¹³æˆ31å¹´" in result:
        result = "2019-04-30"
    
    # å…¨è§’â†’åŠè§’æ•°å­—
    zenkaku_nums = "ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™"
    hankaku_nums = "0123456789"
    trans = str.maketrans(zenkaku_nums, hankaku_nums)
    result = result.translate(trans)
    
    # å…¨è§’â†’åŠè§’è‹±å­—
    zenkaku_alpha = "ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½š"
    hankaku_alpha = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz"
    trans = str.maketrans(zenkaku_alpha, hankaku_alpha)
    result = result.translate(trans)
    
    # é€šè²¨è¨˜å·é™¤å»
    result = result.replace("ï¿¥", "").replace("å††", "").replace("$", "").replace(",", "")
    
    # é›»è©±ç•ªå·æ­£è¦åŒ–
    if "ï¼" in result:
        result = result.replace("ï¼", "-")
    if "(" in result and ")" in result:
        result = result.replace("(", "-").replace(")", "-")
    
    # éƒµä¾¿ç•ªå·å‡¦ç†
    if "ã€’" in result:
        result = result.replace("ã€’", "")
    if len(result) == 7 and result.isdigit():
        result = f"{result[:3]}-{result[3:]}"
    
    # ç©ºç™½å‡¦ç†
    result = result.replace("ã€€", " ").strip()
    
    return result

def test_mock_pipeline_detailed():
    """ãƒ¢ãƒƒã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®è©³ç´°ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ãƒ¢ãƒƒã‚¯ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è©³ç´°ãƒ†ã‚¹ãƒˆ ===\n")
    
    # è¤‡æ•°ã®æ–‡æ›¸ã‚¿ã‚¤ãƒ—ã‚’ãƒ†ã‚¹ãƒˆ
    test_documents = [
        {
            "name": "test_invoice_1.pdf",
            "content": """
            è«‹æ±‚æ›¸
            è«‹æ±‚ç•ªå·: INV-2024-001
            ç™ºè¡Œæ—¥: 2024å¹´1æœˆ15æ—¥
            æ”¯æ‰•æœŸé™: 2024å¹´2æœˆ15æ—¥
            æ ªå¼ä¼šç¤¾ã‚¨ã‚°ã‚¶ãƒ³ãƒ—ãƒ«
            å°è¨ˆ: 100,000å††
            æ¶ˆè²»ç¨: 10,000å††
            åˆè¨ˆ: 110,000å††
            """,
            "expected_type": "INVOICE"
        },
        {
            "name": "test_po_1.pdf", 
            "content": """
            ç™ºæ³¨æ›¸
            ç™ºæ³¨ç•ªå·: PO-2024-001
            ç™ºæ³¨æ—¥: 2024å¹´1æœˆ10æ—¥
            ç´æœŸ: 2024å¹´2æœˆ10æ—¥
            ã‚µãƒ³ãƒ—ãƒ«å•†äº‹æ ªå¼ä¼šç¤¾
            åˆè¨ˆé‡‘é¡: 50,000å††
            """,
            "expected_type": "PURCHASE_ORDER"
        },
        {
            "name": "test_unknown.pdf",
            "content": """
            ä½•ã‹ã®æ–‡æ›¸
            å†…å®¹ãŒã‚ˆãã‚ã‹ã‚‰ãªã„
            """,
            "expected_type": "UNKNOWN"
        }
    ]
    
    for doc in test_documents:
        print(f"ğŸ“„ {doc['name']} ã®ãƒ†ã‚¹ãƒˆ:")
        
        # æ–‡æ›¸åˆ†é¡ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        content = doc['content']
        if "è«‹æ±‚æ›¸" in content or "è«‹æ±‚ç•ªå·" in content:
            doc_type = "INVOICE"
            confidence = 0.9
        elif "ç™ºæ³¨æ›¸" in content or "ç™ºæ³¨ç•ªå·" in content:
            doc_type = "PURCHASE_ORDER"
            confidence = 0.8
        else:
            doc_type = "UNKNOWN"
            confidence = 0.1
        
        # ãƒ™ãƒ³ãƒ€ãƒ¼åˆ¤å®šã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        if "æ ªå¼ä¼šç¤¾ã‚¨ã‚°ã‚¶ãƒ³ãƒ—ãƒ«" in content:
            vendor = "æ ªå¼ä¼šç¤¾ã‚¨ã‚°ã‚¶ãƒ³ãƒ—ãƒ«"
        elif "ã‚µãƒ³ãƒ—ãƒ«å•†äº‹" in content:
            vendor = "æ ªå¼ä¼šç¤¾ã‚µãƒ³ãƒ—ãƒ«å•†äº‹"
        else:
            vendor = "ä¸æ˜"
        
        # æŠ½å‡ºãƒ‡ãƒ¼ã‚¿ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        extracted_fields = {}
        import re
        
        # æ–‡æ›¸ç•ªå·æŠ½å‡º
        doc_no_patterns = [r"è«‹æ±‚ç•ªå·:\s*([A-Z0-9-]+)", r"ç™ºæ³¨ç•ªå·:\s*([A-Z0-9-]+)"]
        for pattern in doc_no_patterns:
            match = re.search(pattern, content)
            if match:
                extracted_fields["document_no"] = match.group(1)
                break
        
        # é‡‘é¡æŠ½å‡º
        amount_patterns = [r"åˆè¨ˆ:\s*([0-9,]+)å††", r"åˆè¨ˆé‡‘é¡:\s*([0-9,]+)å††"]
        for pattern in amount_patterns:
            match = re.search(pattern, content)
            if match:
                extracted_fields["grand_total"] = match.group(1).replace(",", "")
                break
        
        # çµæœè¡¨ç¤º
        print(f"   ğŸ·ï¸  æ–‡æ›¸ç¨®åˆ¥: {doc_type} (ä¿¡é ¼åº¦: {confidence})")
        print(f"   ğŸ¢ ãƒ™ãƒ³ãƒ€ãƒ¼: {vendor}")
        print(f"   ğŸ“Š æŠ½å‡ºãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(extracted_fields)}")
        for field, value in extracted_fields.items():
            print(f"      {field}: {value}")
        
        # æœŸå¾…å€¤ã¨ã®æ¯”è¼ƒ
        if doc_type == doc['expected_type']:
            print(f"   âœ… åˆ†é¡çµæœ: æœŸå¾…é€šã‚Š")
        else:
            print(f"   âŒ åˆ†é¡çµæœ: æœŸå¾…å€¤ {doc['expected_type']}, å®Ÿéš› {doc_type}")
        
        print()

if __name__ == "__main__":
    print("Document Normalizer - è©³ç´°å‹•ä½œç¢ºèªãƒ†ã‚¹ãƒˆ\n")
    
    # å„ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
    test_yaml_config_loading()
    test_vendor_classification()
    test_validation_rules()
    test_transform_functions_detailed()
    test_mock_pipeline_detailed()
    
    print("=== è©³ç´°ãƒ†ã‚¹ãƒˆå®Œäº† ===")
    print("\nğŸ“‹ ç¢ºèªäº‹é …:")
    print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ãŒé©åˆ‡ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹")
    print("âœ… ãƒãƒƒãƒ”ãƒ³ã‚°ãƒ«ãƒ¼ãƒ«ãŒä½“ç³»çš„ã«æ•´ç†ã•ã‚Œã¦ã„ã‚‹")
    print("âœ… æ¤œè¨¼ãƒ«ãƒ¼ãƒ«ãŒåŒ…æ‹¬çš„ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹") 
    print("âœ… å¤‰æ›é–¢æ•°ãŒæ—¥æœ¬èªç‰¹æœ‰ã®å‡¦ç†ã«å¯¾å¿œã—ã¦ã„ã‚‹")
    print("âœ… ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å‡¦ç†ãŒæœŸå¾…é€šã‚Šã«å‹•ä½œã—ã¦ã„ã‚‹")
    print("\nğŸš€ Azureè¨­å®šå¾Œã€å³åº§ã«æœ¬æ ¼é‹ç”¨ãŒå¯èƒ½ã§ã™ï¼")